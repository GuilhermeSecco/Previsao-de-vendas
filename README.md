# üí∞ Previs√£o de Compras Online com SVM

#### Este projeto utiliza Support Vector Machines (SVM) para prever se uma compra online ser√° ou n√£o efetuada, a partir de dados de sess√µes de usu√°rios em um e-commerce. Foram explorados diferentes kernels e t√©cnicas de pr√©-processamento para otimizar a performance dos modelos.

## üìÇ Dataset

#### O conjunto de dados utilizado √© o Online Shoppers Purchasing Intention Dataset, que cont√©m informa√ß√µes sobre comportamento de navega√ß√£o, atributos temporais, dados de visitante e se a compra foi finalizada (Revenue).

Fonte: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/online+shoppers+purchasing+intention+dataset)

# üìä Etapas do Projeto
## 1. An√°lise Explorat√≥ria de Dados (EDA)

#### Inspe√ß√£o inicial de colunas, tipos e valores nulos.

#### Identifica√ß√£o de vari√°veis cont√≠nuas e categ√≥ricas.

#### Visualiza√ß√µes:

    Boxplots (antes e depois da transforma√ß√£o logar√≠tmica).

    Heatmap de correla√ß√£o para vari√°veis cont√≠nuas.
  
    Distribui√ß√£o de vendas (Revenue) e tipos de visitantes (VisitorType).

## 2. Pr√©-Processamento

#### Tratamento de valores nulos (remo√ß√£o direta).

#### Codifica√ß√£o de vari√°veis categ√≥ricas (LabelEncoder para Month e VisitorType).

#### Balanceamento da vari√°vel alvo usando SMOTE para evitar vi√©s do modelo.

#### Padroniza√ß√£o dos dados com StandardScaler (para modelos espec√≠ficos).

## 3. Modelagem

### Foram treinados quatro modelos de SVM:

  |Vers√£o|Kernel|Pr√©-processamento|Observa√ß√µes|
  |:---:|:---:|:---:|:---:|
  |V1|Linear|Sem padroniza√ß√£o|Modelo simples base|
  |V2|Linear|Dados padronizados|Melhoria na converg√™ncia
  |V3|RBF|Padroniza√ß√£o + GridSearchCV|Busca de hiperpar√¢metros ideais (C e gamma)|
  |V4|Polinomial|Padroniza√ß√£o + GridSearchCV|Ajuste de gamma, degree e coef0|

## 4. Avalia√ß√£o de Desempenho

### M√©tricas utilizadas:

    Precision

    Recall

    F1-score

    Accuracy

    AUC

    Matriz de confus√£o

### Resultados resumidos:

  ||Modelo 1|Modelo 2|Modelo 3|Modelo 4|
  |:---|---:|---:|---:|---:|
  |Modelo|            SVM|         SVM|         SVM|         SVM|
  |Kernel|         Linear|      Linear|         RBF|        Poly|
  |Precision|    0.794702|    0.796594|    0.852412|    0.925576|
  |Recall|       0.889831|     0.88975|     0.88623|     0.88377|
  |F1|            0.83958|    0.840599|    0.868992|     0.90419|
  |Accuracy|     0.845797|    0.846597|    0.869496|      0.9004|
  |AUC|          0.849545|    0.850189|    0.869875|    0.901529|

## 5. Visualiza√ß√µes Geradas

### O projeto salva automaticamente alguns gr√°ficos durante a execu√ß√£o:

    Boxplot1.png ‚Äì Boxplots das vari√°veis cont√≠nuas (original).

    Boxplot2.png ‚Äì Boxplots das vari√°veis cont√≠nuas ap√≥s transforma√ß√£o log.

    Heatmap.png ‚Äì Mapa de correla√ß√£o.

    Vendas Efetuadas.png ‚Äì Distribui√ß√£o de compras finalizadas ou n√£o.

    Tipos de Visitantes.png ‚Äì Distribui√ß√£o de tipos de visitantes.

    SMOTE.png ‚Äì Balanceamento da vari√°vel alvo ap√≥s oversampling.

    comparacao_modelos_svm.png - Visualiza√ß√£o dos resultados obtidos

# üõ† Tecnologias Utilizadas

    Python 3

    Pandas, NumPy ‚Äì Manipula√ß√£o e an√°lise de dados.

    Matplotlib, Seaborn ‚Äì Visualiza√ß√µes.

    Scikit-learn ‚Äì Modelagem SVM, m√©tricas, pr√©-processamento.

    Imbalanced-learn (SMOTE) ‚Äì Balanceamento da vari√°vel alvo.

# üöÄ Como Executar

### 1. Clone este reposit√≥rio:
    git clone https://github.com/GuilhermeSecco/Previsao-de-vendas.git
    cd Previsao-de-vendas

### 2. Instale as depend√™ncias:
    pip install -r requirements.txt

### 3. Adicione o arquivo online_shoppers_intention.csv na pasta do projeto.

## 4. Execute o script principal:
    python Previsor-de-vendas.py

# üìå Conclus√£o

#### O uso de SVM demonstrou boa capacidade de classifica√ß√£o para prever compras online, principalmente ap√≥s o balanceamento de dados e ajuste de hiperpar√¢metros. O kernel RBF obteve melhor desempenho geral no conjunto de teste, por fim o kernel linear padronizado tamb√©m apresentou resultados consistentes com menor custo computacional.
